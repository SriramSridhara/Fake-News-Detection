{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import string as st\n",
    "import re       \n",
    "import nltk\n",
    "\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Article_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>statement</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Maria Briceño</td>\n",
       "      <td>Los incendios en California “han llegado a Tij...</td>\n",
       "      <td>13, January 2025</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jeff Cercone</td>\n",
       "      <td>Video shows people in Los Angeles looting from...</td>\n",
       "      <td>13, January 2025</td>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>pants-fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sofia Ahmed</td>\n",
       "      <td>A photo shows a Christian’s home that “miracul...</td>\n",
       "      <td>13, January 2025</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>Image shows former President Barack Obama was ...</td>\n",
       "      <td>13, January 2025</td>\n",
       "      <td>Threads posts</td>\n",
       "      <td>pants-fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Maria Briceño</td>\n",
       "      <td>Esta imagen muestra los incendios en Californi...</td>\n",
       "      <td>13, January 2025</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Madison Czopek</td>\n",
       "      <td>“Blue items that survive” California wildfires...</td>\n",
       "      <td>10, January 2025</td>\n",
       "      <td>Threads posts</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Maria Briceño</td>\n",
       "      <td>Imagen muestra el letrero de Hollywood en Cali...</td>\n",
       "      <td>10, January 2025</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Loreben Tuquero</td>\n",
       "      <td>Video shows a man saving a bunny during the 20...</td>\n",
       "      <td>10, January 2025</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Loreben Tuquero</td>\n",
       "      <td>Image shows the Hollywood sign was on fire as ...</td>\n",
       "      <td>10, January 2025</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>Video shows Dr. Mehmet Oz and rapper Snoop Dog...</td>\n",
       "      <td>10, January 2025</td>\n",
       "      <td>Viral image</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           author  \\\n",
       "0           0    Maria Briceño   \n",
       "1           1     Jeff Cercone   \n",
       "2           2      Sofia Ahmed   \n",
       "3           3   Ciara O'Rourke   \n",
       "4           4    Maria Briceño   \n",
       "5           5   Madison Czopek   \n",
       "6           6    Maria Briceño   \n",
       "7           7  Loreben Tuquero   \n",
       "8           8  Loreben Tuquero   \n",
       "9           9   Ciara O'Rourke   \n",
       "\n",
       "                                           statement              date  \\\n",
       "0  Los incendios en California “han llegado a Tij...  13, January 2025   \n",
       "1  Video shows people in Los Angeles looting from...  13, January 2025   \n",
       "2  A photo shows a Christian’s home that “miracul...  13, January 2025   \n",
       "3  Image shows former President Barack Obama was ...  13, January 2025   \n",
       "4  Esta imagen muestra los incendios en Californi...  13, January 2025   \n",
       "5  “Blue items that survive” California wildfires...  10, January 2025   \n",
       "6  Imagen muestra el letrero de Hollywood en Cali...  10, January 2025   \n",
       "7  Video shows a man saving a bunny during the 20...  10, January 2025   \n",
       "8  Image shows the Hollywood sign was on fire as ...  10, January 2025   \n",
       "9  Video shows Dr. Mehmet Oz and rapper Snoop Dog...  10, January 2025   \n",
       "\n",
       "            source      target  \n",
       "0   Facebook posts       false  \n",
       "1  Instagram posts  pants-fire  \n",
       "2   Facebook posts       false  \n",
       "3    Threads posts  pants-fire  \n",
       "4   Facebook posts       false  \n",
       "5    Threads posts       false  \n",
       "6   Facebook posts       false  \n",
       "7   Facebook posts       false  \n",
       "8     Social Media       false  \n",
       "9      Viral image       false  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full-flop', 'half-true', 'barely-true', 'false', 'true', 'pants-fire', 'mostly-true']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(set(data['target']))\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'barely-true': np.int64(0), 'false': np.int64(1), 'full-flop': np.int64(2), 'half-true': np.int64(3), 'mostly-true': np.int64(4), 'pants-fire': np.int64(5), 'true': np.int64(6)}\n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target column\n",
    "data['target_encoded'] = label_encoder.fit_transform(data['target'])\n",
    "\n",
    "# Get the mapping of labels to encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "print(\"Label Mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          statement  \\\n",
      "0           0  Los incendios en California “han llegado a Tij...   \n",
      "1           1  Video shows people in Los Angeles looting from...   \n",
      "2           2  A photo shows a Christian’s home that “miracul...   \n",
      "3           3  Image shows former President Barack Obama was ...   \n",
      "4           4  Esta imagen muestra los incendios en Californi...   \n",
      "\n",
      "   target_encoded  \n",
      "0               1  \n",
      "1               5  \n",
      "2               1  \n",
      "3               5  \n",
      "4               1  \n"
     ]
    }
   ],
   "source": [
    "# Drop the unnecessary columns\n",
    "data_tfidf = data.drop(columns=['author', 'date', 'source', 'target'])\n",
    "\n",
    "# Optionally reset the index\n",
    "data_tfidf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(data_tfidf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          statement  \\\n",
      "0           0  Los incendios en California “han llegado a Tij...   \n",
      "1           1  Video shows people in Los Angeles looting from...   \n",
      "2           2  A photo shows a Christian’s home that “miracul...   \n",
      "3           3  Image shows former President Barack Obama was ...   \n",
      "4           4  Esta imagen muestra los incendios en Californi...   \n",
      "\n",
      "   target_encoded  \n",
      "0               1  \n",
      "1               5  \n",
      "2               1  \n",
      "3               5  \n",
      "4               1  \n"
     ]
    }
   ],
   "source": [
    "#1.1 Removing non alphabetic characters\n",
    "def rem_punct(text):\n",
    "    return (\"\".join([ch for ch in text if ch not in st.punctuation])) \n",
    "\n",
    "data_tfidf['statement'] = data_tfidf['statement'].apply(lambda x: rem_punct(x))\n",
    "print(data_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          statement  \\\n",
      "0           0  [los, incendios, en, california, “han, llegado...   \n",
      "1           1  [video, shows, people, in, los, angeles, looti...   \n",
      "2           2  [a, photo, shows, a, christian’s, home, that, ...   \n",
      "3           3  [image, shows, former, president, barack, obam...   \n",
      "4           4  [esta, imagen, muestra, los, incendios, en, ca...   \n",
      "\n",
      "   target_encoded  \n",
      "0               1  \n",
      "1               5  \n",
      "2               1  \n",
      "3               5  \n",
      "4               1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3376\\4207863710.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.split('\\s+',text) # \\s+ denotes whitespace characters. so we are splitting based on \\s+ seperator for the whole (max times to split) of text column\n"
     ]
    }
   ],
   "source": [
    "#1.2 Tokenization and lowercase\n",
    "def tokenize(text):\n",
    "    text = re.split('\\s+',text) # \\s+ denotes whitespace characters. so we are splitting based on \\s+ seperator for the whole (max times to split) of text column\n",
    "    return[x.lower() for x in text]\n",
    "\n",
    "data_tfidf['statement'] = data_tfidf['statement'].apply(lambda x: tokenize(x))\n",
    "print(data_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          statement  \\\n",
      "0           0  [incendios, california, “han, llegado, tijuana...   \n",
      "1           1  [video, shows, people, angeles, looting, homes...   \n",
      "2           2  [photo, shows, christian’s, home, “miraculousl...   \n",
      "3           3  [image, shows, former, president, barack, obam...   \n",
      "4           4  [esta, imagen, muestra, incendios, california,...   \n",
      "\n",
      "   target_encoded  \n",
      "0               1  \n",
      "1               5  \n",
      "2               1  \n",
      "3               5  \n",
      "4               1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1.3 Stopword & Smallword removal\n",
    "def rem_small(text):\n",
    "    return[word for word in text if len(word)>3]\n",
    "data_tfidf['statement'] = data_tfidf['statement'].apply(lambda x: rem_small(x))\n",
    "#print(data_tfidf.head())\n",
    "\n",
    "\n",
    "def rem_stopword(text):\n",
    "    return[word for word in text if word not in nltk.corpus.stopwords.words('english')]\n",
    "data_tfidf['statement'] = data_tfidf['statement'].apply(lambda x: rem_stopword(x))\n",
    "print(data_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          statement  \\\n",
      "0           0  [incendios, california, “han, llegado, tijuana...   \n",
      "1           1  [video, show, people, angeles, looting, home, ...   \n",
      "2           2  [photo, show, christian’s, home, “miraculously...   \n",
      "3           3  [image, show, former, president, barack, obama...   \n",
      "4           4  [esta, imagen, muestra, incendios, california,...   \n",
      "\n",
      "   target_encoded  \n",
      "0               1  \n",
      "1               5  \n",
      "2               1  \n",
      "3               5  \n",
      "4               1   (1020,)\n"
     ]
    }
   ],
   "source": [
    "#1.4 Morphological analysis - Lemmatization\n",
    "def lemm(text):\n",
    "    word_net = nltk.WordNetLemmatizer()\n",
    "    return[word_net.lemmatize(word) for word in text]\n",
    "data_tfidf['statement'] = data_tfidf['statement'].apply(lambda x: lemm(x))\n",
    "\n",
    "print(data_tfidf.head(),data_tfidf['statement'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0134   02  100  1000  100000  10game  10year  1174  1200  1300  ...  \\\n",
      "0   0.0  0.0  0.0   0.0     0.0     0.0     0.0   0.0   0.0   0.0  ...   \n",
      "1   0.0  0.0  0.0   0.0     0.0     0.0     0.0   0.0   0.0   0.0  ...   \n",
      "2   0.0  0.0  0.0   0.0     0.0     0.0     0.0   0.0   0.0   0.0  ...   \n",
      "3   0.0  0.0  0.0   0.0     0.0     0.0     0.0   0.0   0.0   0.0  ...   \n",
      "4   0.0  0.0  0.0   0.0     0.0     0.0     0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "   zapeta  zarcillos  zelenskyy  zero  zerotolerance  zillow  zone  \\\n",
      "0     0.0        0.0        0.0   0.0            0.0     0.0   0.0   \n",
      "1     0.0        0.0        0.0   0.0            0.0     0.0   0.0   \n",
      "2     0.0        0.0        0.0   0.0            0.0     0.0   0.0   \n",
      "3     0.0        0.0        0.0   0.0            0.0     0.0   0.0   \n",
      "4     0.0        0.0        0.0   0.0            0.0     0.0   0.0   \n",
      "\n",
      "   zuckerberg  épico  última  \n",
      "0         0.0    0.0     0.0  \n",
      "1         0.0    0.0     0.0  \n",
      "2         0.0    0.0     0.0  \n",
      "3         0.0    0.0     0.0  \n",
      "4         0.0    0.0     0.0  \n",
      "\n",
      "[5 rows x 3707 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure each row in 'statements' is a string\n",
    "data_tfidf['statement'] = data_tfidf['statement'].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Extract the text column for vectorization\n",
    "statements = data_tfidf['statement']\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit and transform the statements\n",
    "X_tfidf = tfidf.fit_transform(statements)\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for visualization\n",
    "import pandas as pd\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "print(tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (816, 3707)\n",
      "Testing size: (204, 3707)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, data['target_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training size:\", X_train.shape)\n",
    "print(\"Testing size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "model1 = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred1 = model1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred2 = model2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_logistic: 0.6911764705882353\n",
      "Accuracy_random_forest: 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred1)\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred2)\n",
    "print(\"Accuracy_logistic:\", accuracy_logistic)\n",
    "print(\"Accuracy_random_forest:\", accuracy_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Logistic:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.69      0.99      0.82       142\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00        32\n",
      "           6       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.69       204\n",
      "   macro avg       0.12      0.17      0.14       204\n",
      "weighted avg       0.48      0.69      0.57       204\n",
      "\n",
      "Classification Report Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.69      0.96      0.80       142\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.29      0.06      0.10        32\n",
      "           6       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.68       204\n",
      "   macro avg       0.16      0.17      0.15       204\n",
      "weighted avg       0.53      0.68      0.58       204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\HP\\OneDrive\\Desktop\\Ram\\Projects\\Fake News Detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report Logistic:\\n\", classification_report(y_test, y_pred1))\n",
    "print(\"Classification Report Random Forest:\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Logistic:\n",
      " [[  0  12   0   0   0   0]\n",
      " [  0 141   0   0   1   0]\n",
      " [  0   7   0   0   0   0]\n",
      " [  0   6   0   0   0   0]\n",
      " [  0  32   0   0   0   0]\n",
      " [  0   5   0   0   0   0]]\n",
      "Confusion Matrix Logistic:\n",
      " [[  0  12   0   0   0   0]\n",
      " [  1 136   0   0   5   0]\n",
      " [  0   7   0   0   0   0]\n",
      " [  0   6   0   0   0   0]\n",
      " [  0  30   0   0   2   0]\n",
      " [  0   5   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(\"Confusion Matrix Logistic:\\n\", confusion_matrix(y_test, y_pred1))\n",
    "print(\"Confusion Matrix Logistic:\\n\", confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model1, 'fake_news_model_logistic.pkl')\n",
    "joblib.dump(model2, 'fake_news_model_random_forest.pkl')\n",
    "\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: [1]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and vectorizer\n",
    "model1 = joblib.load('fake_news_model_logistic.pkl')\n",
    "model2 = joblib.load('fake_news_model_random_forest.pkl')\n",
    "tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Example new statement\n",
    "new_statement = [\"This is an example of a news article.\"]\n",
    "\n",
    "# Transform the new statement into TF-IDF features\n",
    "new_statement_tfidf = tfidf.transform(new_statement)\n",
    "\n",
    "# Predict the target\n",
    "predicted_label = model1.predict(new_statement_tfidf)\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label (decoded): false\n"
     ]
    }
   ],
   "source": [
    "# Invert the label_mapping dictionary for decoding\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Predict the label\n",
    "predicted_label_encoded = model1.predict(new_statement_tfidf)[0]  # Get the encoded label\n",
    "predicted_label = reverse_label_mapping[predicted_label_encoded]  # Decode the label\n",
    "\n",
    "print(\"Predicted label (decoded):\", predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
